{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metagenomic-based Diagnostic for Sepsis (External Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "datasets = cwd / 'datasets'\n",
    "results = cwd / 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/csctan/git_repos/Polymicrobial-Signature-of-Sepsis/datasets/kapusta_genus_raw.csv'),\n",
       " PosixPath('/home/csctan/git_repos/Polymicrobial-Signature-of-Sepsis/datasets/karius_genus_raw.csv'),\n",
       " PosixPath('/home/csctan/git_repos/Polymicrobial-Signature-of-Sepsis/datasets/karius_genus_pathogens.csv')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(datasets.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Since we are using stratified kfold, a validation split is not necesssary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Bifidobacterium</th>\n",
       "      <th>Aeriscardovia</th>\n",
       "      <th>Alloscardovia</th>\n",
       "      <th>Arthrobacter</th>\n",
       "      <th>Kocuria</th>\n",
       "      <th>Glutamicibacter</th>\n",
       "      <th>Citricoccus</th>\n",
       "      <th>Enteractinococcus</th>\n",
       "      <th>Micrococcus</th>\n",
       "      <th>...</th>\n",
       "      <th>Gallicola</th>\n",
       "      <th>Dethiosulfatibacter</th>\n",
       "      <th>Bilophila</th>\n",
       "      <th>Guyparkeria</th>\n",
       "      <th>Sinobaca</th>\n",
       "      <th>Cryptanaerobacter</th>\n",
       "      <th>Marinitoga</th>\n",
       "      <th>Candidatus Endolissoclinum</th>\n",
       "      <th>Luteimicrobium</th>\n",
       "      <th>Paeniclostridium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>52711.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>healthy</td>\n",
       "      <td>29182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>septic</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>septic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>septic</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>septic</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>septic</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>septic</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>septic</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>septic</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 1497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y  Bifidobacterium  Aeriscardovia  Alloscardovia  Arthrobacter  \\\n",
       "0   healthy          52711.0            1.0            1.0         199.0   \n",
       "2   healthy          29182.0            0.0            0.0          35.0   \n",
       "3    septic             33.0            0.0            0.0         215.0   \n",
       "4    septic              3.0            0.0            0.0          35.0   \n",
       "5    septic              2.0            0.0            0.0         299.0   \n",
       "..      ...              ...            ...            ...           ...   \n",
       "76   septic             35.0            1.0            0.0        1285.0   \n",
       "77   septic            128.0            0.0            0.0        1745.0   \n",
       "78   septic             14.0            0.0            0.0          87.0   \n",
       "79   septic            811.0            0.0            0.0         642.0   \n",
       "80   septic             73.0            0.0            0.0         833.0   \n",
       "\n",
       "    Kocuria  Glutamicibacter  Citricoccus  Enteractinococcus  Micrococcus  \\\n",
       "0       3.0              2.0          1.0                1.0          1.0   \n",
       "2       6.0              3.0          0.0                1.0         81.0   \n",
       "3      82.0             59.0          1.0                3.0        144.0   \n",
       "4      23.0             13.0          0.0                0.0         17.0   \n",
       "5      78.0             87.0          0.0                4.0         87.0   \n",
       "..      ...              ...          ...                ...          ...   \n",
       "76    295.0            275.0          7.0               11.0        382.0   \n",
       "77    132.0            120.0          3.0                7.0        142.0   \n",
       "78     30.0             18.0          0.0                3.0         38.0   \n",
       "79    159.0            122.0          5.0                7.0        188.0   \n",
       "80    217.0            177.0          2.0                6.0        263.0   \n",
       "\n",
       "    ...  Gallicola  Dethiosulfatibacter  Bilophila  Guyparkeria  Sinobaca  \\\n",
       "0   ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "2   ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "3   ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "4   ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "5   ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "..  ...        ...                  ...        ...          ...       ...   \n",
       "76  ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "77  ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "78  ...       60.0                  3.0       32.0          0.0       0.0   \n",
       "79  ...        0.0                  0.0        0.0          1.0       1.0   \n",
       "80  ...        0.0                  0.0        0.0          0.0       0.0   \n",
       "\n",
       "    Cryptanaerobacter  Marinitoga  Candidatus Endolissoclinum  Luteimicrobium  \\\n",
       "0                 0.0         0.0                         0.0             0.0   \n",
       "2                 0.0         0.0                         0.0             0.0   \n",
       "3                 0.0         0.0                         0.0             0.0   \n",
       "4                 0.0         0.0                         0.0             0.0   \n",
       "5                 0.0         0.0                         0.0             0.0   \n",
       "..                ...         ...                         ...             ...   \n",
       "76                0.0         0.0                         0.0             0.0   \n",
       "77                0.0         0.0                         0.0             0.0   \n",
       "78                0.0         0.0                         0.0             0.0   \n",
       "79                1.0         1.0                         0.0             0.0   \n",
       "80                0.0         0.0                         1.0             1.0   \n",
       "\n",
       "    Paeniclostridium  \n",
       "0                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "..               ...  \n",
       "76               0.0  \n",
       "77               0.0  \n",
       "78               0.0  \n",
       "79               0.0  \n",
       "80               1.0  \n",
       "\n",
       "[78 rows x 1497 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(datasets / 'kapusta_genus_raw.csv')\n",
    "\n",
    "# Remove NTCs\n",
    "raw_df = raw_df.loc[raw_df.y != 'ntc', :]\n",
    "display(raw_df)\n",
    "\n",
    "X = raw_df.iloc[:, 1:].copy()\n",
    "y = raw_df.iloc[:, 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encode y\n",
    "y.loc[y == 'septic'] = 1\n",
    "y.loc[y == 'healthy'] = 0\n",
    "y = y.astype('int')\n",
    "\n",
    "# Relative abundance\n",
    "X_RA = X.apply(func=lambda x: x / x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Septic</th>\n",
       "      <th>Healthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train fold</th>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test fold</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Septic  Healthy\n",
       "Train fold      44       19\n",
       "Test fold       11        4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "pos = len(y[y == 1])\n",
    "neg = len(y[y == 0])\n",
    "split_sizes = pd.DataFrame({'Septic': [pos - int(pos / n_splits), int(pos / n_splits)], \n",
    "                           'Healthy': [neg - int(neg / n_splits), int(neg / n_splits)]}, index=['Train fold', 'Test fold'])\n",
    "\n",
    "display(split_sizes)\n",
    "\n",
    "# Get negative to positive ratio\n",
    "ratio = sum(y == 0) / sum(y == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested CV for hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from imblearn.metrics import sensitivity_score, specificity_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(X, y, param_dict=False):\n",
    "    np.random.seed(66)\n",
    "    \n",
    "    # Hyperparemeter Optimisation using grid search (F1)\n",
    "    model = XGBClassifier()\n",
    "    n_estimators = range(50, 500, 1)\n",
    "    max_depth = range(1, 10)\n",
    "    gamma = np.linspace(0, 5, 20)\n",
    "    subsample = np.linspace(0.1, 1, 20)\n",
    "    colsample_bytree = np.linspace(0.1, 1, 20)\n",
    "    \n",
    "    param_grid = dict(max_depth=max_depth, \n",
    "                      n_estimators=n_estimators, \n",
    "                      colsample_bytree=colsample_bytree,\n",
    "                      gamma=gamma,\n",
    "                      subsample=subsample,\n",
    "                      scale_pos_weight=[ratio])\n",
    "    \n",
    "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    if not param_dict:\n",
    "        # Inner CV\n",
    "        model = RandomizedSearchCV(model, \n",
    "                                   param_grid, \n",
    "                                   scoring=\"roc_auc\",\n",
    "                                   n_iter=1000,\n",
    "                                   n_jobs=10, \n",
    "                                   cv=inner_cv, \n",
    "                                   verbose=1)\n",
    "\n",
    "        model.fit(X, y)\n",
    "        best_params = model.best_params_\n",
    "        print(best_params)\n",
    "                \n",
    "    else:\n",
    "        model = XGBClassifier(**param_dict)\n",
    "\n",
    "    # Custom metrics\n",
    "    sensitivity = make_scorer(sensitivity_score, average='binary')\n",
    "    specificity = make_scorer(specificity_score, average='binary')\n",
    "    scoring = {'sensitivity': sensitivity, \n",
    "               'specificity': specificity, \n",
    "               'AUROC': 'roc_auc'}\n",
    "    \n",
    "    # Outer CV\n",
    "    outer_results = cross_validate(model, X=X, y=y, cv=outer_cv, scoring=scoring)\n",
    "    outer_results = pd.DataFrame(outer_results).mean()[['test_specificity', 'test_sensitivity', 'test_AUROC']]\n",
    "    \n",
    "    return model, outer_results, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise Model using Neat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=10)]: Done 4980 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.5263157894736842, 'scale_pos_weight': 1.4273504273504274, 'n_estimators': 96, 'max_depth': 2, 'gamma': 1.8421052631578947, 'colsample_bytree': 0.19473684210526315}\n",
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=10)]: Done 4980 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=10)]: Done 4980 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  2.3min\n"
     ]
    }
   ],
   "source": [
    "raw_model, raw_results, raw_params = optimise(X, y)\n",
    "# raw_params = {'subsample': 0.8578947368421053, 'scale_pos_weight': 1.4273504273504274, 'n_estimators': 348, 'max_depth': 7, 'gamma': 2.894736842105263, 'colsample_bytree': 0.24210526315789474}\n",
    "# raw_model, raw_results = optimise(X, y, raw_params)\n",
    "RA_model, RA_results, RA_params = optimise(X_RA, y)\n",
    "# RA_params = {'subsample': 0.7157894736842105, 'scale_pos_weight': 1.4273504273504274, 'n_estimators': 456, 'max_depth': 6, 'gamma': 0.5263157894736842, 'colsample_bytree': 0.33684210526315794}\n",
    "# RA_model, RA_results = optimise(X_RA, y, RA_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame({'Raw': raw_results, 'RA': RA_results}).round(3).T\n",
    "display(metric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Contaminants based on SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import spearmanr\n",
    "import shap\n",
    "\n",
    "\n",
    "def decontam(X_train, y_train, params):\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "\n",
    "    explainer = shap.TreeExplainer(model, feature_pertubation='interventional', model_output='probability', data=X_train)\n",
    "    shap_val = explainer.shap_values(X_train)\n",
    "\n",
    "    to_retain = np.array([True] * X_train.shape[1])\n",
    "    corrs = np.zeros(X_train.shape[1])\n",
    "\n",
    "    for i in range(X_train.shape[1]):\n",
    "        rho = spearmanr(X_train.iloc[:, i], shap_val[:, i])[0]\n",
    "        p = spearmanr(X_train.iloc[:, i], shap_val[:, i])[1]\n",
    "        if rho < 0 and p < 0.05:\n",
    "            to_retain[i] = False\n",
    "\n",
    "        if math.isnan(rho):\n",
    "            corrs[i] = 2\n",
    "        else:\n",
    "            corrs[i] = rho\n",
    "\n",
    "    to_retain = np.logical_and(corrs > 0, corrs != 2)\n",
    "    to_retain = X_train.columns[to_retain]\n",
    "    print(to_retain.shape, to_retain)\n",
    "    \n",
    "    return to_retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decontam using raw_params\n",
    "genera_new = X.columns\n",
    "\n",
    "for _ in range(10):\n",
    "    genera_new = decontam(X.loc[:, genera_new], y, raw_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-human associated pathogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_retain = list(set(genera_new).intersection(set(X_pathogens.columns)))\n",
    "print(to_retain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decontam + pathogens\n",
    "raw_CR = X[to_retain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SHAP summary before removing Cellulomonas and Agrobacterium\n",
    "pre_model = XGBClassifier(**raw_params)\n",
    "pre_model.fit(X=raw_CR, y=y)\n",
    "\n",
    "pre_explainer = shap.TreeExplainer(pre_model, feature_pertubation='interventional', model_output='probability', data=raw_CR)\n",
    "shap_pre = pre_explainer.shap_values(raw_CR)\n",
    "\n",
    "shap.summary_plot(shap_pre, raw_CR, show=False, plot_size=(4, 5), color_bar_label='Unique k-mer Count', max_display=25)\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.set_xlabel('SHAP Value')\n",
    "plt.savefig(results / 'pre_shap.png', dpi=600, format='png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise Datasets\n",
    "RA_CR = raw_CR.apply(func=lambda x: x / x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Neat', X.shape)\n",
    "print('CR', raw_CR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise decontaminated models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pathogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_CR_model, raw_CR_results, raw_CR_params = optimise(raw_CR, y)\n",
    "# raw_params = {'subsample': 0.8578947368421053, 'scale_pos_weight': 1.4273504273504274, 'n_estimators': 348, 'max_depth': 7, 'gamma': 2.894736842105263, 'colsample_bytree': 0.24210526315789474}\n",
    "# raw_model, raw_results = optimise(X, y, raw_params)\n",
    "RA_CR_model, RA_CR_results, RA_CR_params = optimise(RA_CR, y)\n",
    "# RA_params = {'subsample': 0.7157894736842105, 'scale_pos_weight': 1.4273504273504274, 'n_estimators': 456, 'max_depth': 6, 'gamma': 0.5263157894736842, 'colsample_bytree': 0.33684210526315794}\n",
    "# RA_model, RA_results = optimise(X_RA, y, RA_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "300620_STOPPPPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RA_SS_params = optimise(RA_SS_train, y_train)\n",
    "# RA_CR_params = {'colsample_bytree': 0.2, 'gamma': 1, 'max_depth': 4, 'n_estimators': 70, 'scale_pos_weight': 1.4273504273504274, 'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit optimised models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit optimised model on all training data\n",
    "\n",
    "# Decontam\n",
    "raw_SS_model = XGBClassifier(**raw_SS_params)\n",
    "raw_SS_model.fit(X=raw_SS_train, y=y_train)\n",
    "\n",
    "RA_SS_model = XGBClassifier(**RA_SS_params)\n",
    "RA_SS_model.fit(X=RA_SS_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_SS_metric = evaluate(raw_SS_model, raw_SS_test, y_test)\n",
    "RA_SS_metric = evaluate(RA_SS_model, RA_SS_test, y_test)\n",
    "\n",
    "raw_SS_metric = evaluate(raw_SS_model, raw_SS_test, y_test)\n",
    "RA_SS_metric = evaluate(RA_SS_model, RA_SS_test, y_test)\n",
    "\n",
    "metric_df = pd.concat([raw_metric,\n",
    "                       RA_metric,\n",
    "                       raw_SS_metric,\n",
    "                       RA_SS_metric], axis=0)\n",
    "metric_df.index = ['Raw', 'RA', 'Raw SS', 'RA SS']\n",
    "display(metric_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals (non-parametric boostrap estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap with 1001 iterations, 95% CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles(x, alpha=0.05):\n",
    "    low = np.percentile(x, alpha / 2 * 100)\n",
    "    high = np.percentile(x, (1 - alpha / 2) * 100)\n",
    "    \n",
    "    return low, high\n",
    "\n",
    "\n",
    "np.random.seed(66)\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def get_confint(model, X_test, y_test, n_iter=1001):\n",
    "    boot_df = pd.DataFrame({'F1': [0], 'Sensitivity': [0], 'Specificity': [0], 'AUROC' : [0]})\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        boot_X, boot_y = resample(X_test, y_test, n_samples=len(y_test), replace=True, stratify=y_test)\n",
    "        y_pred = model.predict(boot_X)\n",
    "        y_score = model.predict_proba(boot_X)[:, 1]\n",
    "\n",
    "        sensitivity, specificity, _ = sensitivity_specificity_support(y_true=boot_y, y_pred=y_pred, average='binary')\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true=boot_y, y_pred=y_pred, average='binary')\n",
    "        auc = roc_auc_score(y_true=boot_y, y_score=y_score)\n",
    "        temp_df = pd.DataFrame({'F1': [f1], 'Sensitivity': [sensitivity], \n",
    "                                'Specificity': [specificity], 'AUROC' : [auc]})\n",
    "        \n",
    "        boot_df = pd.concat([boot_df, temp_df], axis=0)\n",
    "    \n",
    "    boot_df = boot_df.iloc[1:, :]\n",
    "    \n",
    "    confints = [get_percentiles(boot_df[col]) for col in boot_df.columns]\n",
    "    display(pd.DataFrame(confints, \n",
    "                         columns=['2.5%', '97.5%'], \n",
    "                         index=boot_df.columns).transpose().round(3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw:', end='')\n",
    "get_confint(raw_model, raw_test, y_test)\n",
    "print('RA:', end='')\n",
    "get_confint(RA_model, RA_test, y_test)\n",
    "\n",
    "print('Raw SS:', end='')\n",
    "get_confint(raw_SS_model, raw_SS_test, y_test)\n",
    "print('RA SS:', end='')\n",
    "get_confint(RA_SS_model, RA_SS_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting model using SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "This is a plot of mean absolute SHAP values per feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of SHAP values per Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "explainer_SS = shap.TreeExplainer(raw_SS_model, feature_pertubation='interventional', model_output='probability', data=raw_SS_train)\n",
    "shap_SS = explainer_SS.shap_values(raw_SS_test)\n",
    "\n",
    "explainer_raw = shap.TreeExplainer(raw_model, feature_pertubation='interventional', model_output='probability', data=raw_train)\n",
    "shap_raw = explainer_raw.shap_values(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_SS, raw_SS_test, show=False, plot_size=(4, 5), color_bar_label='Unique k-mer Count', max_display=35)\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.set_xlabel('SHAP Value')\n",
    "plt.savefig(results / 'SS_shap.png', dpi=1200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_raw, raw_test, show=False, plot_size=(4, 5), color_bar_label='Unique k-mer Count', max_display=23)\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "ax.set_xlabel('SHAP Value')\n",
    "plt.savefig(results / 'raw_shap.png', dpi=1200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Features are ranked by importance from top to botttom\n",
    "* feature values are the kmer counts for each genus\n",
    "* SHAP values are the average marginal contributions to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force plot for healthy patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j = 72\n",
    "print(f'Actual Classification {y_test[j]}')\n",
    "print(raw_SS_test.index[j])\n",
    "shap.force_plot(explainer_SS.expected_value, \n",
    "                shap_SS[j,:], \n",
    "                raw_SS_test.iloc[j,:],\n",
    "                show=False,\n",
    "                matplotlib=True)\n",
    "plt.savefig(results / 'SS_force_plot.png', dpi=1200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much does Escherichia drive predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "escherichia_idx = raw_SS_test.columns.get_loc('Escherichia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = raw_SS_model.predict_proba(raw_SS_test)[:, 1]\n",
    "old_auc = roc_auc_score(y_true=y_test, y_score=y_score)\n",
    "new_auc = roc_auc_score(y_true=y_test, y_score=y_score - shap_SS[:, escherichia_idx])\n",
    "print(f\"Before Removing Escherichia = {old_auc}\\nAfter Removing Escherichia = {new_auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mashin",
   "language": "python",
   "name": "mashin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
